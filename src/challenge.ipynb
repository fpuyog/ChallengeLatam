{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Introducción\n",
    "\n",
    "Este proyecto tiene como objetivo resolver un conjunto de tres preguntas relacionadas con el procesamiento y análisis de datos a partir de un archivo JSON. Las preguntas están relacionadas con la medición del tiempo de ejecución y el uso de memoria de las funciones, utilizando herramientas de análisis como `time` y `memory_profiler`.\n",
    "\n",
    "A continuación, se describen las pruebas realizadas para cada pregunta, así como el flujo general de ejecución de las funciones que se desarrollaron para cada una de ellas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suposiciones\n",
    "\n",
    "1. El archivo JSON es accesible a través de Google Drive mediante un enlace de descarga.\n",
    "2. La estructura del JSON es apropiada para las operaciones que se van a realizar (por ejemplo, las funciones de 'q3' requieren un campo específico para el análisis de palabras más frecuentes).\n",
    "3. Las pruebas se ejecutan en un entorno local y los resultados de las métricas de tiempo y memoria son válidos para las condiciones del entorno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flujo de Ejecución\n",
    "\n",
    "1. **Descarga del JSON**: Al ejecutar el código, el archivo JSON es descargado automáticamente desde Google Drive si no se encuentra en la ubicación esperada ('data.json'). Esto se realiza utilizando la función `download_json()` que se encuentra en el archivo `download_json.py`.\n",
    "\n",
    "2. **Ejecución de las Pruebas**: Las tres preguntas (Q1, Q2, Q3) se resuelven ejecutando las funciones correspondientes:\n",
    "    - **Q1 (time)**: Mide el tiempo de ejecución de una función relacionada con el análisis de datos.\n",
    "    - **Q1 (memory)**: Mide la memoria utilizada por la misma función en la pregunta Q1.\n",
    "    - **Q2 (time)**: Realiza una prueba similar para otra función de análisis.\n",
    "    - **Q2 (memory)**: Mide la memoria utilizada por la función correspondiente.\n",
    "    - **Q3 (time)**: Analiza el procesamiento de palabras más frecuentes en el archivo JSON, midiendo el tiempo.\n",
    "    - **Q3 (memory)**: Mide la memoria utilizada en la ejecución de la función que analiza las palabras más frecuentes.\n",
    "\n",
    "3. **Medición del Tiempo y Memoria**: Para cada prueba, se utilizan las herramientas 'time' para medir el tiempo de ejecución y 'memory_profiler' para monitorear el uso de memoria.\n",
    "\n",
    "4. **Resultados**: Los resultados de tiempo y memoria de cada prueba se almacenan en una tabla que es presentada al final del proceso, utilizando la librería 'tabulate' para una visualización clara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Código Principal\n",
    "\n",
    "El código principal en el archivo 'main.py' sigue el siguiente flujo:\n",
    "\n",
    "1. **Verificación de la existencia del archivo JSON**: Al principio, se verifica si el archivo 'data.json' ya existe en el directorio de trabajo. Si no es así, se descarga desde Google Drive.\n",
    "   \n",
    "2. **Ejecutar las pruebas (Q1, Q2, Q3)**: Para cada una de las preguntas (Q1, Q2, Q3), se ejecutan las funciones correspondientes tanto para medir el tiempo como el uso de memoria.\n",
    "\n",
    "3. **Almacenamiento de Resultados**: Los resultados de tiempo y memoria se almacenan en una lista 'results', que se convierte en una tabla al final de la ejecución utilizando 'tabulate'.\n",
    "\n",
    "4. **Mostrar la tabla con los resultados**: La tabla resultante se muestra en formato Markdown, lo que facilita la visualización y comparación de los tiempos de ejecución y la memoria utilizada por cada prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'ChallengeLatam (Python 3.11.9)' requiere el paquete ipykernel.\n",
      "\u001b[1;31mEjecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \n",
      "\u001b[1;31m: 'd:/Users/Checo/Documentos/GitHub/ChallengeLatam/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Configuración del entorno\n",
    "import os\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from tabulate import tabulate\n",
    "from src.q1_time import q1_time\n",
    "from src.q1_memory import q1_memory\n",
    "from src.q2_time import q2_time\n",
    "from src.q2_memory import q2_memory\n",
    "from src.q3_time import q3_time\n",
    "from src.q3_memory import q3_memory\n",
    "import src.download_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ruta para el archivo JSON descargado\n",
    "json_path = os.path.join(os.getcwd(), 'data.json')\n",
    "\n",
    "# Verificar si el archivo ya existe\n",
    "if not os.path.exists(json_path):\n",
    "    print(\"Descargando archivo JSON...\")\n",
    "    src.download_json  # Esto ejecutará el script `download_json.py`\n",
    "else:\n",
    "    print(f\"Archivo JSON encontrado en: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables y tabla de resultados\n",
    "# Número de palabras más frecuentes para Q3\n",
    "top_n = 10  # Puedes ajustar este número según sea necesario\n",
    "\n",
    "# Tabla de resultados\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones a evaluar\n",
    "tests = [\n",
    "    (\"Q1 (time)\", q1_time, [json_path]),\n",
    "    (\"Q1 (memory)\", q1_memory, [json_path]),\n",
    "    (\"Q2 (time)\", q2_time, [json_path]),\n",
    "    (\"Q2 (memory)\", q2_memory, [json_path]),\n",
    "    (\"Q3 (time)\", q3_time, [json_path, top_n]),\n",
    "    (\"Q3 (memory)\", q3_memory, [json_path, top_n])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de pruebas\n",
    "for test_name, func, args in tests:\n",
    "    print(f\"\\nEjecutando {test_name}...\")\n",
    "\n",
    "    # Medir tiempo y memoria\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage((func, args), interval=0.1, timeout=None)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    exec_time = end_time - start_time\n",
    "    peak_memory = max(mem_usage)  # Memoria máxima usada\n",
    "\n",
    "    # Ejecutar la función para obtener el resultado\n",
    "    result = func(*args)\n",
    "    print(f\"Resultado {test_name}: {result}\")\n",
    "\n",
    "    # Almacenar resultados\n",
    "    results.append([test_name, f\"{exec_time:.2f} s\", f\"{peak_memory:.2f} MB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Mostrar la tabla con tabulate\n",
    "headers = [\"Prueba\", \"Tiempo de Ejecución\", \"Memoria Máxima\"]\n",
    "print(\"\\nResultados:\")\n",
    "print(tabulate(results, headers=headers, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'ChallengeLatam (Python 3.11.9)' requiere el paquete ipykernel.\n",
      "\u001b[1;31mEjecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \n",
      "\u001b[1;31m: 'd:/Users/Checo/Documentos/GitHub/ChallengeLatam/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "Ejemplo de Salida\n",
    "\n",
    "| Prueba       | Tiempo de Ejecución | Memoria Máxima |\n",
    "|--------------|---------------------|----------------|\n",
    "| Q1 (time)    | 0.25 s              | 15.56 MB       |\n",
    "| Q1 (memory)  | 0.26 s              | 16.03 MB       |\n",
    "| Q2 (time)    | 0.12 s              | 12.04 MB       |\n",
    "| Q2 (memory)  | 0.13 s              | 12.10 MB       |\n",
    "| Q3 (time)    | 0.35 s              | 18.40 MB       |\n",
    "| Q3 (memory)  | 0.36 s              | 18.55 MB       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusión:\n",
    "    \n",
    "Este proyecto proporciona una forma eficiente de medir tanto el tiempo como el uso de memoria de las funciones que trabajan con un archivo JSON. Las funciones fueron evaluadas de forma independiente y sus métricas fueron comparadas para identificar posibles mejoras. Además, la automatización del proceso de descarga del archivo JSON facilita la repetibilidad de las pruebas en diferentes entornos.\n",
    "\n",
    "Mejoras Posibles:\n",
    " - Optimización del uso de memoria: Se podrían investigar maneras de reducir la memoria utilizada en las funciones más pesadas.\n",
    " - Pruebas adicionales: Se pueden agregar más preguntas para analizar otras métricas del archivo JSON.\n",
    " - Mejoras en la visualización: La tabla de resultados podría mejorarse con más detalles, como una comparación entre diferentes versiones de las funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Referencias\n",
    " - time: Librería estándar de Python para medir el tiempo de ejecución de código.\n",
    " - memory_profiler: Librería para monitorear el uso de memoria de los procesos de Python.\n",
    " - tabulate: Librería para presentar tablas en formato Markdown y otros formatos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChallengeLatam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
